{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "647f53ea",
   "metadata": {},
   "source": [
    "### Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a7d30f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, f1_score,precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4831d2",
   "metadata": {},
   "source": [
    "### Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f77d226d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '3d-printing-model/dataset/dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m datapath = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m3d-printing-model/dataset/dataset.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m DataFrame= \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatapath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '3d-printing-model/dataset/dataset.csv'"
     ]
    }
   ],
   "source": [
    "datapath = r\"3d-printing-model/dataset/dataset.csv\"\n",
    "DataFrame= pd.read_csv(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7400bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"DataFrame loaded successfully.\")\n",
    "DataFrame=pd.DataFrame(DataFrame)\n",
    "DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0116570",
   "metadata": {},
   "source": [
    "### Analyze the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fb1006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the first 5 rows of the DataFrame\n",
    "print(\"First 5 rows of the DataFrame:\")\n",
    "first_five_rows = DataFrame.head(5)\n",
    "first_five_rows_output = pd.DataFrame(first_five_rows.values, columns=first_five_rows.columns, index=first_five_rows.index)\n",
    "print(\"=\"*170)\n",
    "print(first_five_rows_output.to_string())\n",
    "print(\"=\"*170)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c81758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the last 5 rows of the DataFrame\n",
    "print(\"Last 5 rows of the DataFrame:\")\n",
    "last_rows = DataFrame.tail(5)  \n",
    "formatted_output = pd.DataFrame(last_rows.values,  columns=last_rows.columns, index=last_rows.index)\n",
    "print(\"=\"*170)\n",
    "print(formatted_output.to_string())\n",
    "print(\"=\"*170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651400bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of the DataFrame\n",
    "print(f\"The shape of the DataFrame is: {DataFrame.shape[1]} columns\")\n",
    "print(f\"The shape of the DataFrame is: {DataFrame.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0fab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the info of the DataFrame\n",
    "print(\"=\"*80)\n",
    "print(\"DATAFRAME STRUCTURE OVERVIEW\".center(80))\n",
    "print(\"=\"*80)\n",
    "info_str = DataFrame.info()\n",
    "print(info_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cf0410",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*150)\n",
    "print(\"STATISTICAL SUMMARY OF THE DATAFRAME\".center(150))\n",
    "print(\"=\"*150)\n",
    "summary = DataFrame.describe()\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac315ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47860150",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b658f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## checking duplicate values\n",
    "print(\"=\"*50)\n",
    "print(\"DUPLICATE VALUES CHECK\".center(50))\n",
    "print(\"=\"*50)\n",
    "duplicate_count = DataFrame.duplicated().sum()\n",
    "print(f\"Number of duplicate rows in the DataFrame: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5f43c8",
   "metadata": {},
   "source": [
    "#### There are no duplicated rows present in the  DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e34cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking null values in the DataFrame\n",
    "null_values = DataFrame.isnull().sum()\n",
    "print(\"=\"*50)\n",
    "print(\"Null values in each column\".center(50))\n",
    "print(\"=\"*50)\n",
    "print(null_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26790b13",
   "metadata": {},
   "source": [
    "###### From the above code snipett we can say there are zero null values means no null values situated in DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1e3da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## unique values in each column\n",
    "print(\"=\"*240)\n",
    "print(\"Unique values in each column\".center(190))\n",
    "print(\"=\"*240)\n",
    "for col in DataFrame.columns:\n",
    "    print(f\" {col} : {set(DataFrame[col])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac9f227",
   "metadata": {},
   "source": [
    "###### By checking the above values which are unique from each features, there is no inconsistent data in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e59ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##seperating categorical and numerical columns\n",
    "categorical_cols = DataFrame.select_dtypes(include=['object']).columns\n",
    "numerical_cols = DataFrame.select_dtypes(include=['number']).columns\n",
    "\n",
    "print(\"Categorical columns:\", list(categorical_cols))\n",
    "print(\"Numerical columns:\", list(numerical_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e68240",
   "metadata": {},
   "source": [
    "### EXploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1cb69d",
   "metadata": {},
   "source": [
    "#### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d5f6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## printing the nuerical coilumns\n",
    "for col in DataFrame.columns:\n",
    "    print(f\"{col}: {DataFrame[col].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a051e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the count of values in material feature\n",
    "fig, axes = plt.subplots(1, 2, figsize=(9, 8))\n",
    "material_counts = DataFrame['material'].value_counts()\n",
    "infill_values = DataFrame['infill_pattern'].value_counts()\n",
    "\n",
    "axes[0].pie(material_counts, labels=material_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[0].set_title('Material Distribution')\n",
    "axes[1].pie(infill_values, labels=infill_values.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[1].set_title('Infill Pattern Distribution')\n",
    "plt.show()\n",
    "\n",
    "print(DataFrame['material'].value_counts())\n",
    "print('\\n', DataFrame['infill_pattern'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ea6087",
   "metadata": {},
   "source": [
    "##### 1. In Infill pattern Distribution both honeycomb and grid are equally disributed with 51 % and 49%.\n",
    "##### 2. In material distribution both PLA(Polylactic Acid) and ABS(Acrylonitrile Butadiene Styrene) are distributed with 55 % and 45 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460a52df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_cols:\n",
    "    data = pd.Series(DataFrame[col])\n",
    "    print(f\"Skewness of {col} is:\",data.skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587b5d83",
   "metadata": {},
   "source": [
    "##### 1. bed_temperature, elongation and print_speed are right skeweed. Because these features are between skew values 0.5 to 1.\n",
    "##### 2. According to right thumb rule if skewness is less than 0 then it is left skeweed.From features infill_density is left skeweed.\n",
    "##### 3. Remaining all the features are symmetric because the values between 0.1 to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166e1abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10,5))\n",
    "sns.histplot(DataFrame['nozzle_temperature'], ax=ax[0,0], kde=True, color=\"green\", edgecolor=\"black\")\n",
    "ax[0,0].set_ylabel('Frequency')\n",
    "\n",
    "sns.histplot(DataFrame['bed_temperature'], ax=ax[0,1], kde=True, color=\"blue\", edgecolor=\"black\")\n",
    "ax[0,1].set_ylabel('Frequency')\n",
    "# Add skewness text to plot\n",
    "sns.histplot(DataFrame['elongation'], ax=ax[1,0], kde=True, color=\"orange\", edgecolor=\"black\")\n",
    "ax[1,0].set_ylabel('Frequency')\n",
    "\n",
    "sns.histplot(DataFrame['print_speed'], ax=ax[1,1], kde=True, color=\"yellow\", edgecolor=\"black\")\n",
    "ax[1,1].set_ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1079967f",
   "metadata": {},
   "source": [
    "### Distribution of Features:\n",
    "##### 1. The histogram shows values mostly concentrated between 220–230°C with a few lower and higher values in nozzle temperature.\n",
    "##### 2. Elongation Distribution peaks around 1–2%, with some higher values above 2.5%.\n",
    "##### 3. bed temperature Values cluster around 65–75°C, with a long tail stretching toward 100°C.\n",
    "##### 4. Histogram shows clusters at 40–60 mm/s, 60–70 mm/s, and a small group around 110–120 mm/s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c05598",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10,4))\n",
    "\n",
    "ax[0].boxplot([DataFrame['infill_density'], DataFrame['tension_strenght']], tick_labels=['Infill Density', 'Tension Strength'])\n",
    "ax[0].set_title('Boxplot of Infill Density and Tension Strength')\n",
    "\n",
    "ax[1].boxplot([DataFrame['roughness'], DataFrame['fan_speed']], tick_labels=['Roughness', 'Fan Speed'])\n",
    "ax[1].set_title('Boxplot of Roughness and Fan Speed')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c569507d",
   "metadata": {},
   "source": [
    "### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ba8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.countplot(data=DataFrame, x='material', hue='infill_pattern', palette='Set3')\n",
    "plt.show()\n",
    "#cross table for material and infill_pattern\n",
    "cross_tab = pd.crosstab(DataFrame['material'], DataFrame['infill_pattern'])\n",
    "print(cross_tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4401aea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix,axs = plt.subplots(1, 2, figsize=(9, 4))\n",
    "sns.scatterplot(data=DataFrame, x='elongation', y='roughness', hue='material', ax=axs[0], palette='Set1')\n",
    "axs[0].set_title('Roughness vs Tension Strength by Material')\n",
    "\n",
    "sns.scatterplot(data=DataFrame,x='elongation', y='tension_strenght', hue='material', ax=axs[1], palette='Set2')\n",
    "axs[1].set_title('Tension Strength vs Elongation by Material')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5d337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(9,5))\n",
    "sns.boxplot(data=DataFrame, x='material', y='infill_density', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Infill Density by Material')\n",
    "sns.boxplot(data=DataFrame, x='material', y='tension_strenght', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Tension Strength by Material')\n",
    "sns.boxplot(data=DataFrame, x='material', y='roughness', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Roughness by Material')\n",
    "sns.boxplot(data=DataFrame, x='material', y='print_speed', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Fan Speed by Material')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daf9b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking outliers using IQR method for numerical columns\n",
    "Q1 = DataFrame[numerical_cols].quantile(0.25)\n",
    "Q3 = DataFrame[numerical_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = ((DataFrame[numerical_cols] < (Q1 - 1.5 * IQR)) | (DataFrame[numerical_cols] > (Q3 + 1.5 * IQR))).sum()\n",
    "print(\"Number of outliers in each numerical column:\")\n",
    "print(outliers)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "cols_to_plot = [col for col in numerical_cols if col not in ['elongation','layer_height','wall_thickness','infill_pattern','material']]\n",
    "sns.boxplot(data=DataFrame[cols_to_plot], palette='Set3')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf531fb",
   "metadata": {},
   "source": [
    "##### 1. There are 2 outliers in bed temperature feature which can ignore.\n",
    "##### 2. There are 12 outliers in print speed feature. which can be 18 % of data cannot be removed due to less data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1d0e18",
   "metadata": {},
   "source": [
    "#### Multivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc68b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(DataFrame[numerical_cols].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac651fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.pairplot(DataFrame, hue='material', palette='Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbd40aa",
   "metadata": {},
   "source": [
    "## one-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f89e20",
   "metadata": {},
   "source": [
    "####  One-Hot encoding is used for categorical columns. Because both infill pattern and material categorical features are not ordinal categorical columns. Label encoding is used can for ordinal categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828f8ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame_encoded= pd.get_dummies(DataFrame, columns=categorical_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da41edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4593bb0c",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ec27c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = DataFrame_encoded.drop(['material_pla'], axis=1)\n",
    "y = DataFrame_encoded['material_pla']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743c24ea",
   "metadata": {},
   "source": [
    "##### Data is splitted from the DataFrame 'DataFrame_encoded' for two variables x(independent variable) and y(dependent variable).\n",
    "##### Dependent variable is nothing but output in the dataset and independent variable is remaining all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526bf001",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(x, y)\n",
    "imp = model.feature_importances_\n",
    "title = x.columns\n",
    "Top_features = pd.Series(imp,index=title).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.barplot(x=Top_features.values, y=Top_features.index, color='skyblue')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11811ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalizing the data\n",
    "scaler = MinMaxScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "x_scaled = pd.DataFrame(x_scaled, columns=x.columns)\n",
    "x_scaled.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b599e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x_scaled,y,test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a2352f",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83697d8c-24ac-4c45-a9b8-ac0d9cade4f3",
   "metadata": {},
   "source": [
    "#### Since the problem is classification to classsify the material between ABS and PAL, classification algorithm like RandomForestclassifier is used.\n",
    "#### Random Forest: An ensemble of decision trees that predicts by majority vote (classification) or averaging (regression); used for accurate and stable predictions while reducing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9652df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300,400,500],\n",
    "    'max_depth': [2,6,8,10],\n",
    "    'min_samples_split': [2, 5,7],\n",
    "    'min_samples_leaf': [1, 2,4,5],\n",
    "    'max_features': ['sqrt', 'log2', None] \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca779aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid, \n",
    "    scoring='accuracy',\n",
    "    cv=cv,  \n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    error_score='raise'\n",
    ")\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c5ce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = grid_search.predict(x_test)\n",
    "y_pred_train = grid_search.predict(x_train)\n",
    "\n",
    "print(\"test accuracy:\",accuracy_score(y_test,y_pred_test))\n",
    "print(\"train accuracy:\",accuracy_score(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8fcb9c-3441-41d1-bd97-c7f6abe5d3c1",
   "metadata": {},
   "source": [
    "#### K-Fold Cross-Validation:\n",
    "######  A method where data is split into K parts, the model is trained on K‑1 parts and tested on the remaining part, repeated K times.\n",
    "\n",
    "######  It is used  to give a more reliable estimate of model performance than a single train/test split.\n",
    "\n",
    "###### Compared to train/test accuracy: Train/test accuracy shows performance on one split only, which can be optimistic or misleading, while K-Fold CV averages results across folds, showing both expected accuracy and stability (via CV std)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3cff62-1fd4-4534-a725-d5d5414ee2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "scoe = cross_val_score(grid_search,x_scaled,y,cv=cv,scoring='accuracy')\n",
    "print(\"Mean accuracy:\",scoe.mean())\n",
    "print(\"Standard deviation of CV:\",scoe.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99cc43f-3cc5-47a0-ba01-242e82230005",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[0,1,2], yticklabels=[0,1,2])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eddc7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"classification report:\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"precision score:\",precision_score(y_test,y_pred))\n",
    "print(\"F1 score:\",f1_score(y_test,y_pred))\n",
    "print(\"Recall score:\",recall_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330c990b-6316-4934-b34c-2d7123fc3956",
   "metadata": {},
   "source": [
    "#### Case 1 – Good Fit:\n",
    "\n",
    "###### Train accuracy and Test accuracy are both high and similar values.\n",
    "\n",
    "###### CV mean and Train/Test accuracy, CV standard deviation is low <=1, then  model generalizes well.\n",
    "\n",
    "#### Case 2 – Overfitting:\n",
    "\n",
    "###### Train accuracy and  Test accuracy are both high and similar values.\n",
    "\n",
    "###### CV mean much lower than train accuracy, CV  standard deviation is high >=1 or low <=1 model memorizes data, unstable.\n",
    "\n",
    "#### Case 3 – Underfitting:\n",
    "\n",
    "###### Train and Test accuracy both low.\n",
    "\n",
    "###### CV mean and Train/Test accuracy are too low,  CV  standard deviation is high >=1 or low <=1 model too simple, cannot learn patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14912c8-bd19-477f-ad93-dab6a67b7d3b",
   "metadata": {},
   "source": [
    "#### Test and train accuracy is 0.92 and mean accuracy is 0.92 which are similar values and standard deviation is 0.04 which is <=1. So model is stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348c6fc1-e835-4bd2-b2ef-5e51fcc3bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one tree to plot\n",
    "estimator = random_search.estimators_[0]  # First tree in the forest\n",
    "\n",
    "# Plot the tree\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(estimator, \n",
    "          feature_names=data.feature_names, \n",
    "          class_names=data.target_names, \n",
    "          filled=True, \n",
    "          rounded=True,\n",
    "          fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94320710-db52-41dc-a714-c94abf466aef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\n",
    "\n",
    "roc_auc_DT = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label='AUC = %0.2f' % roc_auc_DT)\n",
    "plt.xlabel(\"fpr\")\n",
    "plt.ylabel(\"tpr\")\n",
    "plt.title(\"roc_curve\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5dd279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "file_name='3d_print_model.pkl'\n",
    "joblib.dump(random_search,file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
